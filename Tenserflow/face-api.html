<!DOCTYPE html>
<html>

<head>
  <title>Custom Face Recognition Demo</title>
  <script src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>


  <style>
    #container {
      position: relative;
      width: 640px;
      margin: auto;
    }

    video,
    canvas {
      width: 100%;
      height: 480px;
      border-radius: 8px;
      display: block;
    }

    canvas {
      position: absolute;
      left: 0;
      top: 0;
      pointer-events: none;
    }

    #nameInput,
    #addFaceBtn {
      margin: 10px 5px;
      font-size: 16px;
    }
  </style>
</head>

<body>
  <!-- with face-api.js -->
  <h2>Custom Face Recognition </h2>
  <div id="container">
    <video id="video" autoplay muted></video>
    <canvas id="overlay"></canvas>
  </div>

  <input type="text" id="nameInput" placeholder="Enter friend's name" />
  <button id="addFaceBtn">Add Face</button>
  <p id="status">Loading models...</p>

  <script>
    const video = document.getElementById('video');
    const overlay = document.getElementById('overlay');
    const ctx = overlay.getContext('2d');
    const nameInput = document.getElementById('nameInput');
    const addFaceBtn = document.getElementById('addFaceBtn');
    const status = document.getElementById('status');

    let labeledDescriptors = [];
    let faceMatcher = null;

    async function start() {
      const MODEL_URL = 'https://cdn.jsdelivr.net/gh/justadudewhohacks/face-api.js/weights';
      await faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL);
      await faceapi.nets.faceRecognitionNet.loadFromUri(MODEL_URL);
      await faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL);

      // Start webcam
      const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: { exact: "environment" } } });
      video.srcObject = stream;
      await video.play();

      // Match canvas size to video
      overlay.width = video.videoWidth;
      overlay.height = video.videoHeight;

      status.textContent = "Models loaded! Add friend's face.";
      runRecognitionLoop();
    }

    async function runRecognitionLoop() {
      if (video.paused || video.ended) return setTimeout(runRecognitionLoop, 100);
      console.log(80);
      const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions())
        .withFaceLandmarks()
        .withFaceDescriptors();
      console.log(84, detections);
      ctx.clearRect(0, 0, overlay.width, overlay.height);
      console.log(faceMatcher)

      if (detections.length > 0) {
        const resizedDetections = faceapi.resizeResults(detections, { width: overlay.width, height: overlay.height });

        resizedDetections.forEach(detection => {
          const box = detection.detection.box;
          let label = "Unknown";

          if (faceMatcher) {
            label = faceMatcher.findBestMatch(detection.descriptor).toString();
          }

          // Draw box + label
          ctx.strokeStyle = 'green';
          ctx.lineWidth = 3;
          ctx.strokeRect(box.x, box.y, box.width, box.height);
          ctx.fillStyle = 'green';
          ctx.font = '18px Arial';
          ctx.fillText(label, box.x, box.y > 20 ? box.y - 5 : box.y + 15);
        });
      }


      requestAnimationFrame(runRecognitionLoop);
    }

    addFaceBtn.addEventListener('click', async () => {
      const name = nameInput.value.trim();
      if (!name) {
        alert("Enter a name first!");
        return;
      }

      status.textContent = "Detecting face for " + name + "...";

      // Detect single face in current video frame
      const detection = await faceapi.detectSingleFace(video, new faceapi.TinyFaceDetectorOptions())
        .withFaceLandmarks()
        .withFaceDescriptor();
      console.log(120, detection);

      if (!detection) {
        status.textContent = "No face detected. Try again.";
        return;
      }

      // Save descriptor for this name
      const newDescriptor = detection.descriptor;
      labeledDescriptors.push(new faceapi.LabeledFaceDescriptors(name, [newDescriptor]));

      // Recreate face matcher with updated data
      faceMatcher = new faceapi.FaceMatcher(labeledDescriptors, 0.5);

      status.textContent = `Added face for ${name}. Now show faces to recognize!`;
      nameInput.value = "";
    });

    start();
  </script>
</body>

</html>